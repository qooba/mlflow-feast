{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7474d84b",
   "metadata": {},
   "source": [
    "# Customer propensity to purchase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0967877",
   "metadata": {},
   "source": [
    "The example based on:\n",
    "\n",
    "https://www.kaggle.com/benpowis/customer-propensity-to-purchase\n",
    "\n",
    "Before you start datasets:\n",
    "\n",
    "https://www.kaggle.com/benpowis/customer-propensity-to-purchase?select=testing_sample.csv\n",
    "\n",
    "https://www.kaggle.com/benpowis/customer-propensity-to-purchase?select=training_sample.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5568641e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f10373e-7cd4-4adc-850f-19e097a9651c",
   "metadata": {},
   "source": [
    "# Prepare data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57f3f46-b4e4-483e-b92a-e48ecaa05b81",
   "metadata": {},
   "source": [
    "## Prepare bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b721b95-8d81-46db-babe-d4f9aca394a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '167D825524F0C640',\n",
       "  'HostId': '',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'accept-ranges': 'bytes',\n",
       "   'content-length': '0',\n",
       "   'content-security-policy': 'block-all-mixed-content',\n",
       "   'location': '/mlflow',\n",
       "   'server': 'MinIO',\n",
       "   'vary': 'Origin',\n",
       "   'x-amz-request-id': '167D825524F0C640',\n",
       "   'x-xss-protection': '1; mode=block',\n",
       "   'date': 'Sun, 09 May 2021 21:12:23 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Location': '/mlflow'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "import os\n",
    "import boto3\n",
    "\n",
    "bucket_name=\"propensity\"\n",
    "feast_bucket_name=\"feast\"\n",
    "mlflow_bucket_name=\"mlflow\"\n",
    "s3_client = boto3.client('s3', endpoint_url=os.environ['MLFLOW_S3_ENDPOINT_URL'])\n",
    "s3_client.create_bucket(Bucket=bucket_name)\n",
    "s3_client.create_bucket(Bucket=feast_bucket_name)\n",
    "s3_client.create_bucket(Bucket=mlflow_bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a3b23e-8e61-4592-9d76-5e49d30a71fc",
   "metadata": {},
   "source": [
    "## Convert data to parquets and upload to s3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38650773-45e5-426b-9b2b-b34c1ef20160",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "from pyarrow import fs\n",
    "from datetime import datetime\n",
    "\n",
    "s3 = fs.S3FileSystem(endpoint_override=os.environ.get(\"FEAST_S3_ENDPOINT_URL\"))\n",
    "def s3_upload(filename: str, entity_name: str):\n",
    "    df = pd.read_csv(f\"{filename}.csv\")\n",
    "    df['datetime'] = datetime(2021, 4, 12, 10, 59, 42)\n",
    "    df['created'] = datetime(2021, 4, 12, 10, 59, 42)\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    pq.write_table(table, f'{bucket_name}/{filename}.parquet', filesystem=s3)\n",
    "    entities_table = pa.Table.from_pandas(df[entity_name].to_frame())\n",
    "    pq.write_table(entities_table, f'{bucket_name}/{filename}_entities.parquet', filesystem=s3)\n",
    "    \n",
    "s3_upload('training_sample','UserID')\n",
    "s3_upload('testing_sample','UserID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f325bcc0-f260-43d6-8c19-0da271be0a92",
   "metadata": {},
   "source": [
    "# Feast feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f5228d-eb69-43ee-b530-47c1b31d67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import feast\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8917dce-ea39-4ad4-a09f-dd91d1fd5ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered entity \u001b[1m\u001b[32mUserID\u001b[0m\n",
      "Registered feature view \u001b[1m\u001b[32mpropensity_data\u001b[0m\n",
      "Deploying infrastructure for \u001b[1m\u001b[32mpropensity_data\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "!feast apply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e2b9b8-0f74-413d-b724-69b7ba517c24",
   "metadata": {},
   "source": [
    "### Inspect Feast schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5681e6d-b404-497b-967e-1b25892dd625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\"><tr><th>propensity_data</th><td><table border=\"1\"><tr><th>entities</th><td><table border=\"1\"><thead><tr><th>name</th><th>valueType</th><th>description</th><th>joinKey</th></tr></thead><tbody><tr><td>UserID</td><td>STRING</td><td>user id</td><td>UserID</td></tr></tbody></table></td></tr><tr><th>features</th><td><table border=\"1\"><thead><tr><th>name</th><th>valueType</th></tr></thead><tbody><tr><td>basket_icon_click</td><td>DOUBLE</td></tr><tr><td>basket_add_list</td><td>DOUBLE</td></tr><tr><td>basket_add_detail</td><td>DOUBLE</td></tr><tr><td>sort_by</td><td>DOUBLE</td></tr><tr><td>image_picker</td><td>DOUBLE</td></tr><tr><td>account_page_click</td><td>DOUBLE</td></tr><tr><td>promo_banner_click</td><td>DOUBLE</td></tr><tr><td>detail_wishlist_add</td><td>DOUBLE</td></tr><tr><td>list_size_dropdown</td><td>DOUBLE</td></tr><tr><td>closed_minibasket_click</td><td>DOUBLE</td></tr><tr><td>checked_delivery_detail</td><td>DOUBLE</td></tr><tr><td>checked_returns_detail</td><td>DOUBLE</td></tr><tr><td>sign_in</td><td>DOUBLE</td></tr><tr><td>saw_checkout</td><td>DOUBLE</td></tr><tr><td>saw_sizecharts</td><td>DOUBLE</td></tr><tr><td>saw_delivery</td><td>DOUBLE</td></tr><tr><td>saw_account_upgrade</td><td>DOUBLE</td></tr><tr><td>saw_homepage</td><td>DOUBLE</td></tr><tr><td>device_mobile</td><td>DOUBLE</td></tr><tr><td>device_computer</td><td>DOUBLE</td></tr><tr><td>device_tablet</td><td>DOUBLE</td></tr><tr><td>returning_user</td><td>DOUBLE</td></tr><tr><td>loc_uk</td><td>DOUBLE</td></tr><tr><td>ordered</td><td>DOUBLE</td></tr></tbody></table></td></tr><tr><th>ttl</th><td>8640000s</td></tr><tr><th>input</th><td><table border=\"1\"><tr><th>type</th><td>BATCH_FILE</td></tr><tr><th>eventTimestampColumn</th><td>datetime</td></tr><tr><th>createdTimestampColumn</th><td>created</td></tr><tr><th>fileOptions</th><td><table border=\"1\"><tr><th>fileUrl</th><td>s3://propensity/training_sample.parquet</td></tr></table></td></tr></table></td></tr><tr><th>online</th><td>True</td></tr><tr><th>meta</th><td><table border=\"1\"><tr><th>createdTimestamp</th><td>1970-01-01T00:00:00Z</td></tr></table></td></tr></table></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "from feast import FeatureStore\n",
    "from IPython.core.display import display, HTML\n",
    "import json\n",
    "from json2html import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class FeastSchema:\n",
    "    def __init__(self, repo_path: str):\n",
    "        self.store = FeatureStore(repo_path=repo_path)\n",
    "    \n",
    "    def show_schema(self, skip_meta: bool= False):\n",
    "        feast_schema=self.__project_show_schema(skip_meta)        \n",
    "        display(HTML(json2html.convert(json = feast_schema)))\n",
    "\n",
    "    def show_table_schema(self, table: str, skip_meta: bool= False):\n",
    "        feasture_tables_dictionary=self.__project_show_schema(skip_meta)\n",
    "        display(HTML(json2html.convert(json = {table:feasture_tables_dictionary[table]})))\n",
    "\n",
    "    def __project_show_schema(self, skip_meta: bool= False):\n",
    "        entities_dictionary={}\n",
    "        feast_entities=self.store.list_entities()\n",
    "        for entity in feast_entities:\n",
    "            entity_dictionary=entity.to_dict()\n",
    "            entity_spec=entity_dictionary['spec']\n",
    "            entities_dictionary[entity_spec['name']]=entity_spec\n",
    "        \n",
    "        feasture_tables_dictionary={}\n",
    "        feast_feature_tables=self.store.list_feature_views()\n",
    "        for feature_table in feast_feature_tables:\n",
    "            feature_table_dict=json.loads(str(feature_table))\n",
    "            feature_table_spec=feature_table_dict['spec']\n",
    "            feature_table_name=feature_table_spec['name']\n",
    "            feature_table_spec.pop('name',None)\n",
    "            if 'entities' in feature_table_spec:\n",
    "                feature_table_entities=[]\n",
    "                for entity in feature_table_spec['entities']:\n",
    "                    feature_table_entities.append(entities_dictionary[entity])\n",
    "                feature_table_spec['entities']=feature_table_entities\n",
    "                \n",
    "            if not skip_meta:\n",
    "                feature_table_spec['meta']=feature_table_dict['meta']\n",
    "            else:\n",
    "                feature_table_spec.pop('input',None)\n",
    "                feature_table_spec.pop('ttl',None)\n",
    "                feature_table_spec.pop('online',None)\n",
    "                \n",
    "            feasture_tables_dictionary[feature_table_name]=feature_table_spec\n",
    "        \n",
    "        return feasture_tables_dictionary\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "FeastSchema(\".\").show_schema()\n",
    "#FeastSchema(\".\").show_schema(skip_meta=True)\n",
    "#FeastSchema(\".\").show_table_schema('driver_hourly_stats')\n",
    "#FeastSchema().show_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a450368",
   "metadata": {},
   "source": [
    "## Input parameters for mlflow project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13bd9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import argparse\n",
    "parser= argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--var_smoothing', type=float)\n",
    "\n",
    "args = parser.parse_args()\n",
    "input_params = args.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b81eb8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "input_params = {'var_smoothing':1e-9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78efc9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import sys\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import sklearn\n",
    "from pyarrow import fs\n",
    "from datetime import datetime\n",
    "from feast import FeatureStore\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e7dc6f",
   "metadata": {},
   "source": [
    "## Train and load to mlflow  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc25d052-f11b-4c31-9ad8-4ec71ad0e75b",
   "metadata": {},
   "source": [
    "### Train, Save and Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5b920d0-55ef-465b-8e45-528f9c2bb079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "bucket_name=\"propensity\"\n",
    "filename=\"training_sample\"\n",
    "\n",
    "store = FeatureStore(repo_path=\".\")\n",
    "\n",
    "s3 = fs.S3FileSystem(endpoint_override=os.environ.get(\"FEAST_S3_ENDPOINT_URL\"))\n",
    "entity_df=pd.read_parquet(f'{bucket_name}/{filename}_entities.parquet', filesystem=s3)\n",
    "entity_df[\"event_timestamp\"]=datetime.now()\n",
    "\n",
    "\n",
    "training_df = store.get_historical_features(\n",
    "    entity_df=entity_df, \n",
    "    feature_refs = [\n",
    "        'propensity_data:basket_icon_click',\n",
    "        'propensity_data:basket_add_list',\n",
    "        'propensity_data:basket_add_detail',\n",
    "        'propensity_data:sort_by',\n",
    "        'propensity_data:image_picker',\n",
    "        'propensity_data:account_page_click',\n",
    "        'propensity_data:promo_banner_click',\n",
    "        'propensity_data:detail_wishlist_add',\n",
    "        'propensity_data:list_size_dropdown',\n",
    "        'propensity_data:closed_minibasket_click',\n",
    "        'propensity_data:checked_delivery_detail',\n",
    "        'propensity_data:checked_returns_detail',\n",
    "        'propensity_data:sign_in',\n",
    "        'propensity_data:saw_checkout',\n",
    "        'propensity_data:saw_sizecharts',\n",
    "        'propensity_data:saw_delivery',\n",
    "        'propensity_data:saw_account_upgrade',\n",
    "        'propensity_data:saw_homepage',\n",
    "        'propensity_data:device_mobile',\n",
    "        'propensity_data:device_computer',\n",
    "        'propensity_data:device_tablet',\n",
    "        'propensity_data:returning_user',\n",
    "        'propensity_data:loc_uk',\n",
    "        'propensity_data:ordered'\n",
    "    ],\n",
    ").to_df()\n",
    "\n",
    "predictors = training_df.drop(['propensity_data__ordered','UserID','event_timestamp'], axis=1)\n",
    "targets = training_df['propensity_data__ordered']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, targets, test_size=.3)\n",
    "\n",
    "classifier=GaussianNB(var_smoothing=input_params['var_smoothing'])\n",
    "classifier=classifier.fit(X_train,y_train)\n",
    "\n",
    "predictions=classifier.predict(X_test)\n",
    "\n",
    "conf_matrix=sklearn.metrics.confusion_matrix(y_test,predictions)\n",
    "ac_score=sklearn.metrics.accuracy_score(y_test, predictions)\n",
    "\n",
    "propensity_model_path = 'propensity.joblib'\n",
    "joblib.dump(classifier, propensity_model_path)\n",
    "\n",
    "artifacts = {\n",
    "    \"propensity_model\": propensity_model_path,\n",
    "    \"feature_store\": \"feature_store.yaml\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25073cb6-0306-4ea2-bd76-6a25301afc1b",
   "metadata": {},
   "source": [
    "### Custom MLflow model wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cacf84c-3f80-4d26-be2f-3224b61398bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "import mlflow.pyfunc\n",
    "class PropensityWrapper(mlflow.pyfunc.PythonModel):\n",
    "    \n",
    "    def load_context(self, context):\n",
    "        import joblib\n",
    "        from feast import FeatureStore\n",
    "        import pandas as pd \n",
    "        import os\n",
    "        \n",
    "        self.model = joblib.load(context.artifacts[\"propensity_model\"])\n",
    "        self.store = FeatureStore(repo_path=os.environ.get(\"FEAST_REPO_PATH\"))\n",
    "        \n",
    "    def predict(self, context, model_input):\n",
    "        users=list(model_input.to_dict()[\"UserID\"].values())\n",
    "        \n",
    "        feature_vector = self.store.get_online_features(\n",
    "            feature_refs=[\n",
    "                'propensity_data:basket_icon_click',\n",
    "                'propensity_data:basket_add_list',\n",
    "                'propensity_data:basket_add_detail',\n",
    "                'propensity_data:sort_by',\n",
    "                'propensity_data:image_picker',\n",
    "                'propensity_data:account_page_click',\n",
    "                'propensity_data:promo_banner_click',\n",
    "                'propensity_data:detail_wishlist_add',\n",
    "                'propensity_data:list_size_dropdown',\n",
    "                'propensity_data:closed_minibasket_click',\n",
    "                'propensity_data:checked_delivery_detail',\n",
    "                'propensity_data:checked_returns_detail',\n",
    "                'propensity_data:sign_in',\n",
    "                'propensity_data:saw_checkout',\n",
    "                'propensity_data:saw_sizecharts',\n",
    "                'propensity_data:saw_delivery',\n",
    "                'propensity_data:saw_account_upgrade',\n",
    "                'propensity_data:saw_homepage',\n",
    "                'propensity_data:returning_user',\n",
    "                'propensity_data:loc_uk'\n",
    "            ],\n",
    "            entity_rows=[{\"UserID\": uid} for uid in users]\n",
    "        ).to_dict()\n",
    "        \n",
    "        data=pd.DataFrame.from_dict(feature_vector)\n",
    "        merged_data = pd.merge(model_input,data, how=\"inner\", on=[\"UserID\"], suffixes=('_x', '')).drop(['UserID'], axis=1)\n",
    "        return self.model.predict(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6072abf1-8b69-4b81-8597-872d4773231a",
   "metadata": {},
   "source": [
    "### Conda environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41ce6292-0f17-4012-99aa-ea5b95438b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "from sys import version_info\n",
    "import sklearn\n",
    "import cloudpickle\n",
    "\n",
    "PYTHON_VERSION = f\"{version_info.major}.{version_info.minor}.{version_info.micro}\"\n",
    "\n",
    "conda_env = {\n",
    "    'channels': ['defaults'],\n",
    "    'dependencies': [\n",
    "        f'python={PYTHON_VERSION}',\n",
    "        'pip',\n",
    "        {\n",
    "            'pip':[\n",
    "                'mlflow',\n",
    "                f'scikit-learn=={sklearn.__version__}',\n",
    "                f'cloudpickle=={cloudpickle.__version__}'\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    'name': 'serving_propensity_model'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dbfeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.pyfunc\n",
    "\n",
    "#conda_env=mlflow.pyfunc.get_default_conda_env()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    #mlflow.log_param(\"var_smoothing\", input_params['var_smoothing'])\n",
    "    mlflow.log_metric(\"accuracy_score\", ac_score)\n",
    "    \n",
    "    tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "    if tracking_url_type_store != \"file\":\n",
    "        mlflow.pyfunc.log_model(\"model\",\n",
    "                                 registered_model_name=\"propensity_model\",\n",
    "                                 python_model=PropensityWrapper(),\n",
    "                                 artifacts=artifacts,\n",
    "                                 conda_env=conda_env)\n",
    "    else:\n",
    "        mlflow.pyfunc.log_model(\"model\",\n",
    "                                 path=my_model_path,\n",
    "                                 python_model=PropensityWrapper(),\n",
    "                                 artifacts=artifacts,\n",
    "                                 conda_env=conda_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a123e4",
   "metadata": {},
   "source": [
    "## Export train code "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45fc67f",
   "metadata": {},
   "source": [
    "The above code will be exported to the python file using nbdev library (export, hide, default_exp keyworkd are needed ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da45f940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted mlflow_feast.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0944f3ee",
   "metadata": {},
   "source": [
    "## Train from command using mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03b9f418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'propensity' does not exist. Creating a new experiment\n",
      "2021/05/09 21:15:22 INFO mlflow.projects.utils: === Created directory /tmp/tmp_l3rorpu for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2021/05/09 21:15:22 INFO mlflow.projects.backend.local: === Running command 'python3 ./mlflow_feast/train.py --var_smoothing 1e-9' in run with ID 'ffaaf42e82d24f21a532b521343c8492' === \n",
      "Successfully registered model 'propensity_model'.\n",
      "2021/05/09 21:15:35 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: propensity_model, version 1\n",
      "Created version '1' of model 'propensity_model'.\n",
      "2021/05/09 21:15:35 INFO mlflow.projects: === Run (ID 'ffaaf42e82d24f21a532b521343c8492') succeeded ===\n"
     ]
    }
   ],
   "source": [
    "!mlflow run . --no-conda --experiment-name=\"propensity\" -P var_smoothing=1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbdc9203-6ab2-4315-89b4-a518e1b3480a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: REDIS_CONNECTION_STRING=redis.qooba.svc.cluster.local:6379,db=0\n",
      "Materializing feature view \u001b[1m\u001b[32mpropensity_data\u001b[0m from \u001b[1m\u001b[32m2021-03-22 23:42:00+00:00\u001b[0m to \u001b[1m\u001b[32m2021-06-22 23:42:00+00:00\u001b[0m done!\n"
     ]
    }
   ],
   "source": [
    "%env REDIS_CONNECTION_STRING=redis.qooba.svc.cluster.local:6379,db=0\n",
    "!feast materialize 2021-03-22T23:42:00 2021-06-22T23:42:00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4334050-fda7-4aba-83e8-e3a7b4350803",
   "metadata": {},
   "source": [
    "# Test locally "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aeacc9",
   "metadata": {},
   "source": [
    "## Load from mlflow repository and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d045a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: FEAST_REPO_PATH=.\n"
     ]
    }
   ],
   "source": [
    "%env FEAST_REPO_PATH=.\n",
    "import mlflow.sklearn\n",
    "#sk_model = mlflow.pyfunc.load_model(\"runs:/96771d893a5e46159d9f3b49bf9013e2/sk_models\")\n",
    "#sk_model = mlflow.pyfunc.load_model(\"s3://mlflow/mlruns/2/5610d55090ec4b499a9cd14fd409c05d/artifacts/model\")\n",
    "#sk_model = mlflow.pyfunc.load_model(\"models:/propensity_model/13\")\n",
    "sk_model = mlflow.pyfunc.load_model(\"models:/propensity_model/Production\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad3f09cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.DataFrame.from_dict(data=[\n",
    "    {\"UserID\": \"a720-6b732349-a720-4862-bd21-644732\",\n",
    "     'propensity_data:device_mobile': 1.0,\n",
    "     'propensity_data:device_computer': 0.0,\n",
    "     'propensity_data:device_tablet': 0.0\n",
    "    }\n",
    "])\n",
    "\n",
    "res=sk_model.predict(data)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d044ab8a-f5b5-4a5d-ab65-5cb41693f598",
   "metadata": {},
   "source": [
    "# Test microservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fd517f2-f00d-4be7-9b75-34308d188ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url=\"http://mlflow-serving.qooba.svc.cluster.local:5000/invocations\"\n",
    "\n",
    "headers={\n",
    "    'Content-Type': 'application/json; format=pandas-records'\n",
    "}\n",
    "\n",
    "data=[\n",
    "    {\"UserID\": \"a720-6b732349-a720-4862-bd21-644732\",\n",
    "     'propensity_data:device_mobile': 1.0,\n",
    "     'propensity_data:device_computer': 0.0,\n",
    "     'propensity_data:device_tablet': 0.0\n",
    "    }\n",
    "]\n",
    "\n",
    "response=requests.post(url, data=json.dumps(data), headers=headers)\n",
    "response.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
